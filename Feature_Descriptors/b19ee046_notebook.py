# -*- coding: utf-8 -*-
"""B19EE046_Notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xTLSmo_wZliZf_N5DGAGn1VIGENkFpe6
"""

from google.colab import drive
drive.mount('/content/drive')

import cv2
import numpy as np
from google.colab.patches import cv2_imshow
import os
import time
import math

def feature_detector(g1,g2,g3,mode='sift'):
  if mode=='sift':
    fd = cv2.xfeatures2d.SIFT_create()
    kp1, des1 = fd.detectAndCompute(g1, None)
    kp2, des2 = fd.detectAndCompute(g2, None)
    kp3, des3 = fd.detectAndCompute(g3, None)
  elif mode=='orb':
    fd = cv2.ORB_create()
    kp1, des1 = fd.detectAndCompute(g1, None)
    kp2, des2 = fd.detectAndCompute(g2, None)
    kp3, des3 = fd.detectAndCompute(g3, None)
  elif mode=='akaze':
    fd = cv2.AKAZE_create()
    kp1, des1 = fd.detectAndCompute(g1, None)
    kp2, des2 = fd.detectAndCompute(g2, None)
    kp3, des3 = fd.detectAndCompute(g3, None)
  else:
    print("Its not available")
    return 0,0,0,0,0,0
  return kp1,kp2,kp3,des1,des2,des3

def feature_detector_pairwise(img1, img2, mode='sift'):
  img1 = cv2.resize(img1,(int(img1.shape[0]*0.75),int(img1.shape[1]*0.5)))
  img2 = cv2.resize(img2,(int(img2.shape[0]*0.75),int(img2.shape[1]*0.5)))
  g1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
  g2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
  if mode=='sift':
    fd = cv2.xfeatures2d.SIFT_create()
    kp1, des1 = fd.detectAndCompute(g1, None)
    kp2, des2 = fd.detectAndCompute(g2, None)
    matches = feature_matcher(des1,des2,'BF_plain')
    matches = sorted(matches, key = lambda x:x.distance)
    img = cv2.drawMatches(img1, kp1, img2, kp2, matches[:15], img2, flags=2)
    cv2_imshow(img)
  elif mode=='kaze':
    fd = cv2.KAZE_create()
    kp1, des1 = fd.detectAndCompute(g1, None)
    kp2, des2 = fd.detectAndCompute(g2, None)
    matches = feature_matcher(des1,des2,'BF_plain')
    matches = sorted(matches, key = lambda x:x.distance)
    img = cv2.drawMatches(img1, kp1, img2, kp2, matches[:15], img2, flags=2)
    cv2_imshow(img)
  elif mode=='akaze':
    fd = cv2.AKAZE_create()
    kp1, des1 = fd.detectAndCompute(g1, None)
    kp2, des2 = fd.detectAndCompute(g2, None)
    matches = feature_matcher(des1,des2,'BF_plain')
    matches = sorted(matches, key = lambda x:x.distance)
    img = cv2.drawMatches(img1, kp1, img2, kp2, matches[:15], img2, flags=2)
    cv2_imshow(img)
  else:
    print("Its not available")

def feature_matcher(p1,p2,mode='BF'):
  if mode=='BF':
    bf = cv2.BFMatcher(cv2.NORM_L2)
    matches = bf.knnMatch(p1, p2, k=2)
  elif mode=='BF_plain':
    bf = cv2.BFMatcher(cv2.NORM_L2)
    matches = bf.match(p1, p2)
  elif mode=='FLANN':
    index_params = dict(algorithm=0, trees=5)
    search_params = dict(checks=50)
    flann = cv2.FlannBasedMatcher(index_params, search_params)
    matches = flann.knnMatch(p1, p2, k=2)
  elif mode=='HTM':
    matcher = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_FLANNBASED)
    matcher.setCrossCheck(True)
    matches = matcher.match(p1, p2)
  else:
    print("Not Available")
    return None
  return matches

def matcher_test(matches,mode='Ratio'):
  good_matches = []
  if mode=='Ratio':
    for m, n in matches:
      if m.distance < 0.75 * n.distance:
        good_matches.append(m)
  elif mode=='Lowe':
    for m in matches:
      if len(m) == 2 and m[0].distance < m[1].distance * 0.7:
        good_matches.append(m[0])
  else:
    print("Not available")
  return good_matches

def hough_transform(img):
    def loop_body(x, y):
        if edges[x][y] != 0:
            for i in range(len(theta_range)):
                r = x * np.cos(theta_range[i]) + y * np.sin(theta_range[i])
                accumulator[int(r + diagonal)][i] += 1
    
    edges = cv2.Canny(img, 50, 200, apertureSize=3)
    theta_range = np.deg2rad(np.arange(-90, 90))
    h, w = edges.shape
    diagonal = int(math.sqrt(h ** 2 + w ** 2))
    rho = np.linspace(-diagonal, diagonal, diagonal * 2)
    accumulator = np.zeros((len(rho), len(theta_range)))
    np.fromfunction(np.vectorize(loop_body), (h, w), dtype=int)
    threshold = 0.8 * np.max(accumulator)
    y_idxs, x_idxs = np.where(accumulator >= threshold)
    rhos = rho[y_idxs]
    thetas = theta_range[x_idxs]
    lines = np.column_stack((rhos, thetas))
    return lines

def draw_lines(img, lines):
    for line in lines:
        r, theta = line
        a = np.cos(theta)
        b = np.sin(theta)
        x0 = a * r
        y0 = b * r
        x1 = int(x0 + 1000 * (-b))
        y1 = int(y0 + 1000 * (a))
        x2 = int(x0 - 1000 * (-b))
        y2 = int(y0 - 1000 * (a))
        cv2.line(img, (x1, y1), (x2, y2), (0, 0, 255), 2)
    return img

def custom_hough_transform(img):
    t = time.time()
    lines = hough_transform(img)
    img = draw_lines(img, lines)
    new_t = time.time()
    return (new_t - t), img

def opencv_hough_transform(img):
    t = time.time()
    edges = cv2.Canny(img, 50, 200, apertureSize=3)
    lines = cv2.HoughLines(edges, 1, np.pi / 180, 100)
    for r_theta in lines:
        arr = np.array(r_theta[0], dtype=np.float64)
        r, theta = arr
        a = np.cos(theta)
        b = np.sin(theta)
        x0 = a * r
        y0 = b * r
        x1 = int(x0 + 1000 * (-b))
        y1 = int(y0 + 1000 * (a))
        x2 = int(x0 - 1000 * (-b))
        y2 = int(y0 - 1000 * (a))
        cv2.line(img, (x1, y1), (x2, y2), (0, 0, 255), 2)
    new_t = time.time()
    return (new_t - t), img

"""#2A - Q1

##Ex-1
"""

scene_img = cv2.imread('/content/drive/MyDrive/CV_Assignment_2/Problem-1/logo matching/Ex1/levis.jpg')
logos_list = os.listdir('/content/drive/MyDrive/CV_Assignment_2/Problem-1/logo matching/Ex1/logos')

for i in logos_list:
  logo_img = cv2.imread(os.path.join('/content/drive/MyDrive/CV_Assignment_2/Problem-1/logo matching/Ex1/logos',i))
  feature_detector_pairwise(scene_img,logo_img,'sift')

for i in logos_list:
  logo_img = cv2.imread(os.path.join('/content/drive/MyDrive/CV_Assignment_2/Problem-1/logo matching/Ex1/logos',i))
  feature_detector_pairwise(scene_img,logo_img,'kaze')

for i in logos_list:
  logo_img = cv2.imread(os.path.join('/content/drive/MyDrive/CV_Assignment_2/Problem-1/logo matching/Ex1/logos',i))
  feature_detector_pairwise(scene_img,logo_img,'akaze')

"""##Ex-2"""

scene_img = cv2.imread('/content/drive/MyDrive/CV_Assignment_2/Problem-1/logo matching/Ex2/starbucks.jpeg')
logos_list = os.listdir('/content/drive/MyDrive/CV_Assignment_2/Problem-1/logo matching/Ex2/logos')

for i in logos_list:
  logo_img = cv2.imread(os.path.join('/content/drive/MyDrive/CV_Assignment_2/Problem-1/logo matching/Ex2/logos',i))
  feature_detector_pairwise(scene_img,logo_img,'sift')

for i in logos_list:
  logo_img = cv2.imread(os.path.join('/content/drive/MyDrive/CV_Assignment_2/Problem-1/logo matching/Ex2/logos',i))
  feature_detector_pairwise(scene_img,logo_img,'kaze')

for i in logos_list:
  logo_img = cv2.imread(os.path.join('/content/drive/MyDrive/CV_Assignment_2/Problem-1/logo matching/Ex2/logos',i))
  feature_detector_pairwise(scene_img,logo_img,'akaze')

"""#2A - Q2"""

img = cv2.imread('/content/drive/MyDrive/CV_Assignment_2/Problem-1/logo matching/Ex2/logos/hp.jpg', 0)
custom_t, custom_img = custom_hough_transform(img)
opencv_t, opencv_img = opencv_hough_transform(img)
cv2_imshow(custom_img)
print(custom_t)
cv2_imshow(opencv_img)
print(opencv_t)
cv2_imshow(custom_img-opencv_img)

"""#2A - Q3

##Ex-1
"""

img_ref = cv2.imread('/content/drive/MyDrive/CV_Assignment_2/Problem-3/example-1/reference.png')
img_p = cv2.resize(cv2.imread('/content/drive/MyDrive/CV_Assignment_2/Problem-3/example-1/perfect/penetration_checkLin.png'),(img_ref.shape[1],img_ref.shape[0]))
img_f = cv2.resize(cv2.imread('/content/drive/MyDrive/CV_Assignment_2/Problem-3/example-1/faulty/Element_Optimised_Colour_ShapeLin.png'),(img_ref.shape[1],img_ref.shape[0]))
img_refg = cv2.cvtColor(img_ref, cv2.COLOR_BGR2GRAY)
img_pg = cv2.cvtColor(img_p, cv2.COLOR_BGR2GRAY)
img_fg = cv2.cvtColor(img_f, cv2.COLOR_BGR2GRAY)
cv2_imshow(img_ref - img_p)
print(" ")
cv2_imshow(img_ref - img_f)
print(" ")
cv2_imshow(img_refg - img_pg)
print(" ")
cv2_imshow(img_refg - img_fg)

cv2_imshow((img_ref/img_p)**2)
print(" ")
cv2_imshow((img_ref/img_f)**2)
print(" ")
cv2_imshow((img_refg/img_pg)**5)
print(" ")
cv2_imshow((img_refg/img_fg)**5)

cv2_imshow(np.log(img_ref/img_p))
print(" ")
cv2_imshow(np.log(img_ref/img_f))

"""##Ex-2"""

img_ref = cv2.imread('/content/drive/MyDrive/CV_Assignment_2/Problem-3/example-2/Orginal.png')
img_p = cv2.resize(cv2.imread('/content/drive/MyDrive/CV_Assignment_2/Problem-3/example-2/perfect/Orginal_Lin.png'),(img_ref.shape[1],img_ref.shape[0]))
img_f = cv2.resize(cv2.imread('/content/drive/MyDrive/CV_Assignment_2/Problem-3/example-2/faulty/2ndOrderElements.png'),(img_ref.shape[1],img_ref.shape[0]))
img_refg = cv2.cvtColor(img_ref, cv2.COLOR_BGR2GRAY)
img_pg = cv2.cvtColor(img_p, cv2.COLOR_BGR2GRAY)
img_fg = cv2.cvtColor(img_f, cv2.COLOR_BGR2GRAY)
cv2_imshow(img_ref - img_p)
print(" ")
cv2_imshow(img_ref - img_f)
print(" ")
cv2_imshow(img_refg - img_pg)
print(" ")
cv2_imshow(img_refg - img_fg)

cv2_imshow((img_ref/img_p)**5)
print(" ")
cv2_imshow((img_ref/img_f)**5)
print(" ")
cv2_imshow((img_refg/img_pg)**2)
print(" ")
cv2_imshow((img_refg/img_fg)**2)

"""# 2B - Q3"""

# Load images
img1 = cv2.imread('/content/drive/MyDrive/CV_Assignment_2/problem-3/1a.jpeg')
img2 = cv2.imread('/content/drive/MyDrive/CV_Assignment_2/problem-3/1b.jpeg')
img3 = cv2.imread('/content/drive/MyDrive/CV_Assignment_2/problem-3/1c.jpeg')
cv2_imshow(img1)
cv2_imshow(img2)
cv2_imshow(img3)

# Convert to grayscale
gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
gray3 = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY)
cv2_imshow(gray1)
cv2_imshow(gray2)
cv2_imshow(gray3)

kp1,kp2,kp3,des1,des2,des3 = feature_detector(gray1,gray2,gray3,'orb')
kp_img1 = cv2.drawKeypoints(gray1, kp1, None, flags=0)
kp_img2 = cv2.drawKeypoints(gray2, kp2, None, flags=0)
kp_img3 = cv2.drawKeypoints(gray3, kp3, None, flags=0)
cv2_imshow(kp_img1)
cv2_imshow(kp_img2)
cv2_imshow(kp_img3)

matches = feature_matcher(des1,des2,'BF')
good_matches = matcher_test(matches,'Ratio')
src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)
dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)
H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)

# determine output size based on input images and transformation matrix
h1, w1 = img1.shape[:2]
h2, w2 = img2.shape[:2]
pts1 = np.float32([[0, 0], [0, h1], [w1, h1], [w1, 0]]).reshape(-1, 1, 2)
pts2 = np.float32([[0, 0], [0, h2], [w2, h2], [w2, 0]]).reshape(-1, 1, 2)
pts2_transformed = cv2.perspectiveTransform(pts2, H)
pts = np.concatenate((pts1, pts2_transformed), axis=0)
[x_min, y_min] = np.int32(pts.min(axis=0).ravel() - 0.5)
[x_max, y_max] = np.int32(pts.max(axis=0).ravel() + 0.5)
warp_size = (x_max - x_min, y_max - y_min)

# adjust transformation matrix to shift image content to left
shift = np.array([[1, 0, -x_min], [0, 1, -y_min], [0, 0, 1]])
H_shifted = shift.dot(H)

# warp images and combine
warp_img = cv2.warpPerspective(img1, H_shifted, warp_size)
warp_img[-y_min:h2-y_min, -x_min:w2-x_min] = img2
cv2_imshow(warp_img)